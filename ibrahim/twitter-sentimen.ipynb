{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None\n",
      "----------------\n",
      "target column unique = [1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/yaedin/twitter-disaster/main/raw/disaster_tweets.csv')\n",
    "print(data.info())\n",
    "print('----------------')\n",
    "print(f\"target column unique = {data.target.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6090 entries, 2762 to 4701\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    6090 non-null   object\n",
      " 1   target  6090 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 142.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1523 entries, 54 to 1296\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    1523 non-null   object\n",
      " 1   target  1523 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 35.7+ KB\n",
      "None\n",
      "train df:\n",
      "0    57.405583\n",
      "1    42.594417\n",
      "Name: target, dtype: float64\n",
      "test df:\n",
      "0    55.54826\n",
      "1    44.45174\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibrago/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "train.drop('id', axis=1, inplace=True)\n",
    "train.drop('keyword', axis=1, inplace=True)\n",
    "train.drop('location', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "test.drop('keyword', axis=1, inplace=True)\n",
    "test.drop('location', axis=1, inplace=True)\n",
    "\n",
    "print(train.info())\n",
    "print(test.info())\n",
    "print(\"train df:\")\n",
    "print(train['target'].value_counts(normalize=True) * 100)\n",
    "print(\"test df:\")\n",
    "print(test['target'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibrago/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>70 Years After Atomic Bombs Japan Still Strugg...</td>\n",
       "      <td>1</td>\n",
       "      <td>years after atomic bombs japan still struggles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Suspect in latest US theatre attack had psycho...</td>\n",
       "      <td>1</td>\n",
       "      <td>suspect in latest us theatre attack had psycho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>Is it bad to say that I'm kinda afraid of stor...</td>\n",
       "      <td>1</td>\n",
       "      <td>is it bad to say that i'm kinda afraid of stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>å¤} New Ladies Shoulder Tote #Handbag Faux Lea...</td>\n",
       "      <td>0</td>\n",
       "      <td>new ladies shoulder tote handbag faux leather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>My parents don't believe in the dream. Sad.</td>\n",
       "      <td>0</td>\n",
       "      <td>my parents don't believe in the dream sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "2762  70 Years After Atomic Bombs Japan Still Strugg...       1   \n",
       "470   Suspect in latest US theatre attack had psycho...       1   \n",
       "6269  Is it bad to say that I'm kinda afraid of stor...       1   \n",
       "964   å¤} New Ladies Shoulder Tote #Handbag Faux Lea...       0   \n",
       "2907        My parents don't believe in the dream. Sad.       0   \n",
       "\n",
       "                                             text_clean  \n",
       "2762  years after atomic bombs japan still struggles...  \n",
       "470   suspect in latest us theatre attack had psycho...  \n",
       "6269  is it bad to say that i'm kinda afraid of stor...  \n",
       "964   new ladies shoulder tote handbag faux leather ...  \n",
       "2907          my parents don't believe in the dream sad  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "  # get rid of all unwanted punctuation and digits\n",
    "  text = text.replace(\"´\", \"'\")\n",
    "  digi_punct = \"[^a-zA-Z' ]\"\n",
    "  text = re.sub(digi_punct, \" \", text)\n",
    "  text = \" \".join(text.split())\n",
    "  text = text.lower()\n",
    "  return text\n",
    "import re\n",
    "train[\"text_clean\"] = train[\"text\"].apply(clean_text)\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ibrago/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/ibrago/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>wo_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>70 Years After Atomic Bombs Japan Still Strugg...</td>\n",
       "      <td>1</td>\n",
       "      <td>years after atomic bombs japan still struggles...</td>\n",
       "      <td>70 Years After Atomic Bombs Japan Still Strugg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Suspect in latest US theatre attack had psycho...</td>\n",
       "      <td>1</td>\n",
       "      <td>suspect in latest us theatre attack had psycho...</td>\n",
       "      <td>Suspect latest US theatre attack psychological...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>Is it bad to say that I'm kinda afraid of stor...</td>\n",
       "      <td>1</td>\n",
       "      <td>is it bad to say that i'm kinda afraid of stor...</td>\n",
       "      <td>Is bad say I'm kinda afraid storms storm???? help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>å¤} New Ladies Shoulder Tote #Handbag Faux Lea...</td>\n",
       "      <td>0</td>\n",
       "      <td>new ladies shoulder tote handbag faux leather ...</td>\n",
       "      <td>å¤} New Ladies Shoulder Tote #Handbag Faux Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>My parents don't believe in the dream. Sad.</td>\n",
       "      <td>0</td>\n",
       "      <td>my parents don't believe in the dream sad</td>\n",
       "      <td>My parents believe dream. Sad.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "2762  70 Years After Atomic Bombs Japan Still Strugg...       1   \n",
       "470   Suspect in latest US theatre attack had psycho...       1   \n",
       "6269  Is it bad to say that I'm kinda afraid of stor...       1   \n",
       "964   å¤} New Ladies Shoulder Tote #Handbag Faux Lea...       0   \n",
       "2907        My parents don't believe in the dream. Sad.       0   \n",
       "\n",
       "                                             text_clean  \\\n",
       "2762  years after atomic bombs japan still struggles...   \n",
       "470   suspect in latest us theatre attack had psycho...   \n",
       "6269  is it bad to say that i'm kinda afraid of stor...   \n",
       "964   new ladies shoulder tote handbag faux leather ...   \n",
       "2907          my parents don't believe in the dream sad   \n",
       "\n",
       "                                           wo_stopwords  \n",
       "2762  70 Years After Atomic Bombs Japan Still Strugg...  \n",
       "470   Suspect latest US theatre attack psychological...  \n",
       "6269  Is bad say I'm kinda afraid storms storm???? help  \n",
       "964   å¤} New Ladies Shoulder Tote #Handbag Faux Lea...  \n",
       "2907                     My parents believe dream. Sad.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "my_stopwords = stopwords.words(\"english\")\n",
    "train[\"wo_stopwords\"] = train[\"text\"].apply(\n",
    "    lambda text: \" \".join([word for word in text.split() if word not in my_stopwords])\n",
    ")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ibrago/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/ibrago/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train[\"lemmatized\"] = train[\"wo_stopwords\"].apply(\n",
    "  lambda text: \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Noches El-Bestia '@Alexis_Sanchez: happy to se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>My room looks like a tornado passed through it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>@DetroitPls interested to see who will win thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>And here I was complaining about Phoenix Mode ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>Winter Desolation of Death is also on Tumblr: ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "54    Noches El-Bestia '@Alexis_Sanchez: happy to se...       0\n",
       "6741  My room looks like a tornado passed through it...       0\n",
       "567   @DetroitPls interested to see who will win thi...       0\n",
       "1988  And here I was complaining about Phoenix Mode ...       0\n",
       "2538  Winter Desolation of Death is also on Tumblr: ...       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for further use it makes sense to define train and test data for vectorization\n",
    "X_train = train['lemmatized']\n",
    "y_train = train['target']\n",
    "X_test = test['text']\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer training data 0.7479187247369256\n",
      "TfidfVectorizer training data 0.7332228807214597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipeline1 = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "pipeline2 = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "print(\"CountVectorizer training data\", cross_val_score(pipeline1, X_train, y_train, scoring='f1').mean())\n",
    "print(\"TfidfVectorizer training data\", cross_val_score(pipeline2, X_train, y_train, scoring='f1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer testing data 0.7113637015791398\n",
      "TfidfVectorizer testing data 0.7022425843816874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipeline1 = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "pipeline2 = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "print(\"CountVectorizer testing data\", cross_val_score(pipeline1, X_test, y_test, scoring='f1').mean())\n",
    "print(\"TfidfVectorizer testing data\", cross_val_score(pipeline2, X_test, y_test, scoring='f1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', ' ', 'a', 'm', ' ', 'a', ' ', 'c', 'o', 'w']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try with own text\n",
    "list(\"I am a cow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fire california']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "text.append(\"fire california\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_fit = vectorizer.fit_transform(X_train)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_fit, y_train)\n",
    "X_test_fit = vectorizer.transform(X_test)\n",
    "textpred = vectorizer.transform(text)\n",
    "y_pred = logreg.predict(textpred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tweet):\n",
    "    text = []\n",
    "    text.append(tweet)\n",
    "    textpred = vectorizer.transform(text)\n",
    "    y_pred = logreg.predict(textpred)\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "test('in california is sunshine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_fit, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fit = vectorizer.transform(X_test)\n",
    "y_pred = logreg.predict(X_test_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = logreg.score(X_train_fit, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipeline1 = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "pipeline2 = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "print(\"CountVectorizer\", cross_val_score(pipeline1, X_test, y_test).mean())\n",
    "print(\"TfidfVectorizer\", cross_val_score(pipeline2, X_test, y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
